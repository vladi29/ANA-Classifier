{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladi29/ANA-Classifier/blob/main/binary_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fL1C90aZn8oo"
      },
      "outputs": [],
      "source": [
        "# Universidad Simon Bolivar - 26 de Enero de 2022\n",
        "# Trabajo final de grado: Clasificador de patrones ANA\n",
        "# Vladimir Alfaro - 1510023\n",
        "\n",
        "# Creacion, entrenamiento y prueba de una red para clasificacion binaria\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import h5py\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Cleaning the VRAM memory\n",
        "#torch.cuda.empty_cache()\n",
        "#torch.cuda.reset_peak_memory_stats(device=None)\n",
        "#print(\"Espacio disponible en GPU (Gb): \", torch.cuda.memory_allocated()*1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X-B7phRhoslB"
      },
      "outputs": [],
      "source": [
        "#----------Paths----------\n",
        "\n",
        "images_path = r'drive/MyDrive/Colab_Notebooks/Tesis/Augmented_dataset/'\n",
        "original_labels_path = r'drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/original_labels.csv'\n",
        "original_names_path = r'drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/original_names.csv'\n",
        "augmented_labels_path = r'drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/augmented_labels.csv'\n",
        "augmented_names_path = r'drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/augmented_names.csv'\n",
        "original_ds_path = r'drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/Original_dataset.h5'\n",
        "augmented_ds_path =r'drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/Augmented_dataset.h5'\n",
        "\n",
        "original_names = pd.read_csv(original_names_path, header = None)\n",
        "original_names = original_names.values.tolist()\n",
        "\n",
        "labels_raw = pd.read_csv(original_labels_path, header = None)\n",
        "labels_raw = labels_raw.values.tolist()\n",
        "original_labels = []\n",
        "for label in labels_raw:\n",
        "  original_labels.append(label[0])\n",
        "\n",
        "augmented_names = pd.read_csv(augmented_names_path, header = None)\n",
        "augmented_names = augmented_names.values.tolist()\n",
        "\n",
        "labels_raw = pd.read_csv(augmented_labels_path, header = None)\n",
        "labels_raw = labels_raw.values.tolist()\n",
        "augmented_labels = []\n",
        "for label in labels_raw:\n",
        "  augmented_labels.append(label[0])\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kWWVzqgtfj-x",
        "outputId": "0f503bab-3b3a-4f4d-d744-66810d29808a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negativos:  4067 Positivos:  10486\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPx0lEQVR4nO3df6zddX3H8edLKv6WFntHWNutLNZt1WWRnUCNiXNioLCFkswQzByVNDZR55wz23D7gwX8Q7NNJoniOnEW4wTGzGgmjjSFhWRZK6eyIT/GuBOBdmCvttRtZGr1vT/Op+6At/Tce+49p6f3+Uhu7vf7+Xy+5/v+3Fvu63x/nC+pKiRJS9sLxl2AJGn8DANJkmEgSTIMJEkYBpIkYNm4C5ivlStX1tq1a8ddhiRNjL17936rqqZm65vYMFi7di3dbnfcZUjSxEjy2LH6PE0kSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQm+BPIkjROyXj2u1j/PzKPDCRJhoEkyTCQJGEYSJIwDCRJDBAGST6T5ECS+/vaTk+yM8kj7fuK1p4k1yWZTnJfkrP7ttncxj+SZHNf+y8l+Vrb5rpkXNfoJWnpGuTI4LPAxue0XQnsqqp1wK62DnAhsK59bQWuh154AFcB5wLnAFcdDZA25l192z13X5KkRXbcMKiqu4GDz2neBGxvy9uBS/rab6ye3cDyJGcCFwA7q+pgVR0CdgIbW98rq2p3VRVwY99rSZJGZL7XDM6oqifb8lPAGW15FfBE37h9re352vfN0j6rJFuTdJN0Z2Zm5lm6JOm5hr6A3N7RL9Jn4n5sX9uqqlNVnampWf+fzpKkeZhvGHyzneKhfT/Q2vcDa/rGrW5tz9e+epZ2SdIIzTcMdgBH7wjaDNzW1355u6toA3C4nU66Azg/yYp24fh84I7W950kG9pdRJf3vZYkaUSO+6C6JF8A3gysTLKP3l1BHwFuSbIFeAy4tA2/HbgImAaeAa4AqKqDSa4B7mnjrq6qoxel30PvjqWXAF9uX5KkEUot1iPwFlmn06lutzvuMiQtUZP41NIke6uqM1ufn0CWJBkGkiTDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJDBkGST6Q5IEk9yf5QpIXJzkryZ4k00luTnJqG/uitj7d+tf2vc6HWvvDSS4YbkqSpLmadxgkWQX8NtCpqtcBpwCXAR8Frq2qVwOHgC1tky3AodZ+bRtHkvVtu9cCG4FPJjllvnVJkuZu2NNEy4CXJFkGvBR4EngLcGvr3w5c0pY3tXVa/3lJ0tpvqqrvVtWjwDRwzpB1SZLmYN5hUFX7gT8FHqcXAoeBvcDTVXWkDdsHrGrLq4An2rZH2vhX9bfPss2zJNmapJukOzMzM9/SJUnPMcxpohX03tWfBfwk8DJ6p3kWTVVtq6pOVXWmpqYWc1eStKQMc5rorcCjVTVTVd8Hvgi8EVjeThsBrAb2t+X9wBqA1n8a8O3+9lm2kSSNwDBh8DiwIclL27n/84AHgbuAt7Uxm4Hb2vKOtk7rv7OqqrVf1u42OgtYB3xliLokSXO07PhDZldVe5LcCnwVOALcC2wDvgTclOTDre2GtskNwOeSTAMH6d1BRFU9kOQWekFyBHhvVf1gvnVJkuYuvTfnk6fT6VS32x13GZKWqGQ8+x3mT3aSvVXVma3PTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkMGQZJlie5Ncm/JXkoyRuSnJ5kZ5JH2vcVbWySXJdkOsl9Sc7ue53NbfwjSTYPOylJ0twMe2TwceAfqurngF8EHgKuBHZV1TpgV1sHuBBY1762AtcDJDkduAo4FzgHuOpogEiSRmPeYZDkNOBNwA0AVfW9qnoa2ARsb8O2A5e05U3AjdWzG1ie5EzgAmBnVR2sqkPATmDjfOuSJM3dMEcGZwEzwF8luTfJp5O8DDijqp5sY54CzmjLq4An+rbf19qO1f5jkmxN0k3SnZmZGaJ0SVK/YcJgGXA2cH1VvR74H/7/lBAAVVVADbGPZ6mqbVXVqarO1NTUQr2sJC15w4TBPmBfVe1p67fSC4dvttM/tO8HWv9+YE3f9qtb27HaJUkjMu8wqKqngCeS/GxrOg94ENgBHL0jaDNwW1veAVze7iraABxup5PuAM5PsqJdOD6/tUmSRmTZkNu/D/h8klOBrwNX0AuYW5JsAR4DLm1jbwcuAqaBZ9pYqupgkmuAe9q4q6vq4JB1SZLmIL3T+pOn0+lUt9sddxmSlqhkPPsd5k92kr1V1Zmtz08gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJBYgDJKckuTeJH/f1s9KsifJdJKbk5za2l/U1qdb/9q+1/hQa384yQXD1iRJmpuFODJ4P/BQ3/pHgWur6tXAIWBLa98CHGrt17ZxJFkPXAa8FtgIfDLJKQtQ1zEl4/mSpBPVUGGQZDXwq8Cn23qAtwC3tiHbgUva8qa2Tus/r43fBNxUVd+tqkeBaeCcYeqSJM3NsEcGfw78PvDDtv4q4OmqOtLW9wGr2vIq4AmA1n+4jf9R+yzbPEuSrUm6SbozMzNDli5JOmreYZDk14ADVbV3Aet5XlW1rao6VdWZmpoa1W4l6aS3bIht3whcnOQi4MXAK4GPA8uTLGvv/lcD+9v4/cAaYF+SZcBpwLf72o/q30aSNALzPjKoqg9V1eqqWkvvAvCdVfUbwF3A29qwzcBtbXlHW6f131lV1dova3cbnQWsA74y37okSXM3zJHBsfwBcFOSDwP3Aje09huAzyWZBg7SCxCq6oEktwAPAkeA91bVDxahLknSMaT35nzydDqd6na789p2XLd5TuiPWtIsJvHvSJK9VdWZrc9PIEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSQwRBknWJLkryYNJHkjy/tZ+epKdSR5p31e09iS5Lsl0kvuSnN33Wpvb+EeSbB5+WpKkuRjmyOAI8MGqWg9sAN6bZD1wJbCrqtYBu9o6wIXAuva1FbgeeuEBXAWcC5wDXHU0QCRJozHvMKiqJ6vqq235v4CHgFXAJmB7G7YduKQtbwJurJ7dwPIkZwIXADur6mBVHQJ2AhvnW5ckae4W5JpBkrXA64E9wBlV9WTrego4oy2vAp7o22xfaztW+2z72Zqkm6Q7MzOzEKVLkliAMEjycuBvgd+pqu/091VVATXsPvpeb1tVdaqqMzU1tVAvK0lL3lBhkOSF9ILg81X1xdb8zXb6h/b9QGvfD6zp23x1aztWuyRpRIa5myjADcBDVfWxvq4dwNE7gjYDt/W1X97uKtoAHG6nk+4Azk+yol04Pr+1SZJGZNkQ274R+E3ga0n+pbX9IfAR4JYkW4DHgEtb3+3ARcA08AxwBUBVHUxyDXBPG3d1VR0coi5J0hyld1p/8nQ6nep2u/PaNlngYgY0oT9qSbOYxL8jSfZWVWe2Pj+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjiBwiDJxiQPJ5lOcuW465GkpeSECIMkpwCfAC4E1gNvT7J+vFVJ0tJxQoQBcA4wXVVfr6rvATcBm8ZckyQtGcvGXUCzCniib30fcO5zByXZCmxtq/+d5OF57m8l8K15bjtvyaj3+CxjmfOYLbU5L7X5whKcczLUnH/6WB0nShgMpKq2AduGfZ0k3arqLEBJE8M5n/yW2nzBOS+kE+U00X5gTd/66tYmSRqBEyUM7gHWJTkryanAZcCOMdckSUvGCXGaqKqOJPkt4A7gFOAzVfXAIu5y6FNNE8g5n/yW2nzBOS+YVNVivK4kaYKcKKeJJEljZBhIkk7uMDjeIy6SvCjJza1/T5K1o69y4Qww399N8mCS+5LsSnLMe44nxaCPMUny60kqycTfhjjInJNc2n7XDyT561HXuNAG+Lf9U0nuSnJv+/d90TjqXChJPpPkQJL7j9GfJNe1n8d9Sc4eeqdVdVJ+0bsQ/R/AzwCnAv8KrH/OmPcAn2rLlwE3j7vuRZ7vrwAvbcvvnuT5DjrnNu4VwN3AbqAz7rpH8HteB9wLrGjrPzHuukcw523Au9vyeuAb4657yDm/CTgbuP8Y/RcBXwYCbAD2DLvPk/nIYJBHXGwCtrflW4HzkjF/Tnj+jjvfqrqrqp5pq7vpfZ5jkg36GJNrgI8C/zvK4hbJIHN+F/CJqjoEUFUHRlzjQhtkzgW8si2fBvznCOtbcFV1N3DweYZsAm6snt3A8iRnDrPPkzkMZnvExapjjamqI8Bh4FUjqW7hDTLfflvovbOYZMedczt8XlNVXxplYYtokN/za4DXJPmnJLuTbBxZdYtjkDn/MfCOJPuA24H3jaa0sZnrf+/HdUJ8zkCjleQdQAf45XHXspiSvAD4GPDOMZcyasvonSp6M72jv7uT/EJVPT3WqhbX24HPVtWfJXkD8Lkkr6uqH467sElxMh8ZDPKIix+NSbKM3uHlt0dS3cIb6JEeSd4K/BFwcVV9d0S1LZbjzfkVwOuAf0zyDXrnVndM+EXkQX7P+4AdVfX9qnoU+Hd64TCpBpnzFuAWgKr6Z+DF9B5id7Ja8Ef4nMxhMMgjLnYAm9vy24A7q12dmUDHnW+S1wN/QS8IJv08MhxnzlV1uKpWVtXaqlpL7zrJxVXVHU+5C2KQf9d/R++ogCQr6Z02+vooi1xgg8z5ceA8gCQ/Ty8MZkZa5WjtAC5vdxVtAA5X1ZPDvOBJe5qojvGIiyRXA92q2gHcQO9wcprexZrLxlfxcAac758ALwf+pl0nf7yqLh5b0UMacM4nlQHnfAdwfpIHgR8Av1dVk3rEO+icPwj8ZZIP0LuY/M4JfmNHki/QC/SV7TrIVcALAarqU/Sui1wETAPPAFcMvc8J/nlJkhbIyXyaSJI0IMNAkmQYSJIMA0kShoEkCcNAkoRhIEkC/g+XoI//F8dvpQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Preparando la data para usar Cross Entropy Loss con balanceo de clases\n",
        "augmented_data = True\n",
        "\n",
        "if(augmented_data):\n",
        "  labels = augmented_labels\n",
        "  names = augmented_names\n",
        "else:\n",
        "  labels = original_labels\n",
        "  names = original_names\n",
        "\n",
        "binary_labels = []\n",
        "for label in labels:\n",
        "  _class = [0, 0]\n",
        "  if label == 'Negative':\n",
        "    _class[0], _class[1] = 1, 0\n",
        "  else: \n",
        "    _class[0], _class[1] = 0, 1\n",
        "  binary_labels.append(_class)\n",
        "\n",
        "Negatives, Positives= 0, 0\n",
        "\n",
        "weights, histogram_data = [], []\n",
        "\n",
        "for labels in binary_labels:  \n",
        "  if labels[0] == 1:\n",
        "    Negatives += 1\n",
        "    histogram_data.append(0)\n",
        "  if labels[1] == 1:\n",
        "    Positives += 1\n",
        "    histogram_data.append(1)\n",
        "\n",
        "# Creacion de un vector de pesos para balancear las clases\n",
        "weights.append(Negatives)\n",
        "weights.append(Positives)\n",
        "weights = np.array(weights)\n",
        "weights = 1/weights\n",
        "weights = weights/np.sum(weights)\n",
        "weights = torch.tensor(weights, dtype=torch.float)\n",
        "print(\"Negativos: \", Negatives, \"Positivos: \", Positives)\n",
        "plt.hist(histogram_data, facecolor = 'blue', alpha = 1)\n",
        "plt.show()\n",
        "\n",
        "#Division de la data para entrenar, validar y probar la red\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(names, binary_labels, test_size = 0.2, random_state=123)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a945dZFhA9Zy",
        "outputId": "788565fd-2e71-4ddb-e04f-01e96c52c961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "445\n",
            "445\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing Inmuno21 dataset\n",
        "\n",
        "path = 'drive/MyDrive/Colab_Notebooks/Tesis/Inmuno21_ds'\n",
        "\n",
        "binary_names = []   \n",
        "binary_labels = []   \n",
        "\n",
        "for image_name in os.listdir(path):\n",
        "    binary_names.append(image_name)\n",
        "    binary_labels.append('_'.join(image_name.split('_')[:-1]))\n",
        "\n",
        "print(len(binary_labels))\n",
        "print(len(binary_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "CrILoC1ZBE73",
        "outputId": "b277103b-f62f-4cf2-d1bd-353845a76729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30, 415]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def Binary_labeling(label_list):\n",
        "  binary_labels = []\n",
        "  for label in label_list:\n",
        "    _class = [0, 0]\n",
        "    if label == 'AC0':\n",
        "      _class[0], _class[1] = 1, 0\n",
        "    else: \n",
        "      _class[0], _class[1] = 0, 1\n",
        "    binary_labels.append(_class)\n",
        "\n",
        "  return binary_labels\n",
        "\n",
        "def Binary_plot(binary_labels):\n",
        "  \n",
        "  labels_names = (\"Negativos\", \"Positivos\")\n",
        "  \n",
        "  labels_array = np.array(binary_labels)\n",
        "  classes = np.shape(labels_array)[1]\n",
        "  weights, bar_plot_data = [], []\n",
        "\n",
        "  for _class in range(0, classes):\n",
        "    bar_plot_data.append(np.count_nonzero(labels_array[:, _class] == 1))\n",
        "\n",
        "  print(bar_plot_data)\n",
        "  plt.bar(range(0, classes), bar_plot_data, color = 'blue')\n",
        "  plt.xticks(range(0, classes), labels_names, color='black', rotation=45, fontweight='bold', fontsize='10', horizontalalignment='right')\n",
        "  plt.show()\n",
        "\n",
        "binary_labels = Binary_labeling(binary_labels)\n",
        "binary_weights = Binary_plot(binary_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3MYbv7o-nooV"
      },
      "outputs": [],
      "source": [
        "#Clase Dataset Personaliazdo\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataset, names, labels, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.names = names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        image_name = self.names[idx][0].split('.')[0]\n",
        "        image = self.dataset.get(image_name)[:] \n",
        "        image = torch.tensor(image)  \n",
        "        label = torch.tensor(self.labels[idx])\n",
        "        #label = torch.reshape(label, (2, ))   #label = torch.reshape(label, (1, )) para BCEloss\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "Inmuno21_dataset = h5py.File(\"drive/MyDrive/Colab_Notebooks/Tesis/Preprocessing/Inmuno21_dataset.h5\", 'r')\n",
        "\n",
        "class CustomImageValidationDataset(Dataset):\n",
        "    def __init__(self, dataset, names, labels, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.names = names\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        image_name = self.names[idx]\n",
        "        image = self.dataset.get(image_name)[:] \n",
        "        image = torch.tensor(image)  \n",
        "        label = torch.tensor(self.labels[idx])    \n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "#Creando Dataloader para los conjuntos de entrenamiento y prueba\n",
        "\n",
        "if(augmented_data):\n",
        "  dataset = h5py.File(augmented_ds_path, 'r')\n",
        "else:\n",
        "  dataset = h5py.File(original_ds_path, 'r')\n",
        "\n",
        "\n",
        "Batch_size = 64\n",
        "\n",
        "train_data = CustomImageDataset(dataset, x_train, y_train) # transform=Custom_transform\n",
        "train_dataloader = DataLoader(train_data, batch_size=Batch_size, shuffle=True, num_workers=2)   #-------------------------Cambiar el shuffle-----------------------\n",
        "\n",
        "val_data = CustomImageValidationDataset(Inmuno21_dataset, binary_names, binary_labels)\n",
        "val_dataloader = DataLoader(val_data, batch_size=Batch_size, shuffle=False, num_workers=2)       #-------------------------Cambiar el shuffle----------------------- \n",
        "\n",
        "test_data = CustomImageDataset(dataset, x_test, y_test)\n",
        "test_dataloader = DataLoader(test_data, batch_size=Batch_size, shuffle=True, num_workers=2)    #-------------------------Cambiar el shuffle-----------------------\n",
        "\n",
        "# images, labels = next(iter(train_dataloader))\n",
        "# plt.imshow(images[0])\n",
        "# print(labels[0])\n",
        "# plt.show()\n",
        "\n",
        "# images, labels = next(iter(val_dataloader))\n",
        "# plt.imshow(images[0])\n",
        "# print(labels[0])\n",
        "# plt.show()\n",
        "\n",
        "# images, labels = next(iter(test_dataloader))\n",
        "# plt.imshow(images[0])\n",
        "# print(labels[0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gWnld0xbgGqz"
      },
      "outputs": [],
      "source": [
        "# Clase para adaptar modelo pre-entrenados\n",
        "\n",
        "class MyExtendedNet(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        super(MyExtendedNet, self).__init__()\n",
        "        self.pretrained = pretrained_model\n",
        "        self.new_layer = nn.Sequential( nn.Linear(1000, 1000),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(0.4),\n",
        "                                        nn.Linear(1000, 1000),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(0.4),\n",
        "                                        nn.Linear(1000, 500),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(0.4),\n",
        "                                        nn.Linear(500, 100),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(0.4),\n",
        "                                        nn.Linear(100, 10),\n",
        "                                        nn.ReLU(),\n",
        "                                        nn.Dropout(0.4),\n",
        "                                        nn.Linear(10, 2),\n",
        "                                        nn.Sigmoid())     \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = self.pretrained(x)\n",
        "        x = self.new_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NEs1Hj1WNypA"
      },
      "outputs": [],
      "source": [
        "# Metricas\n",
        "\n",
        "def Metrics(Y, Y_hat, device, average):\n",
        "    average = average\n",
        "    Y_hat = (Y_hat > 0.7)\n",
        "\n",
        "    # GPU\n",
        "    if (device == torch.device('cuda:0')):\n",
        "      acc = accuracy_score(Y.cpu().detach().numpy(), Y_hat.cpu().detach().numpy())\n",
        "      prec = precision_score(Y.cpu().detach().numpy(), Y_hat.cpu().detach().numpy(), average=average, zero_division=0)\n",
        "      recall = recall_score(Y.cpu().detach().numpy(), Y_hat.cpu().detach().numpy(), average=average, zero_division=0)\n",
        "      f1 = f1_score(Y.cpu().detach().numpy(), Y_hat.cpu().detach().numpy(), average=average, zero_division=0) \n",
        "    # CPU\n",
        "    else:\n",
        "      acc = accuracy_score(Y.detach().numpy(), Y_hat.detach().numpy())\n",
        "      prec = precision_score(Y.detach().numpy(), Y_hat.detach().numpy(), average=average, zero_division=0)\n",
        "      recall = recall_score(Y.detach().numpy(), Y_hat.detach().numpy(), average=average, zero_division=0)\n",
        "      f1 = f1_score(Y.detach().numpy(), Y_hat.detach().numpy(), average=average, zero_division=0)\n",
        "\n",
        "    return(acc, prec, recall, f1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HEOqCFMPN4Gj"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs, device, scheduler):\n",
        "\n",
        "    model.to(device)\n",
        "    training_loss, validation_loss = [], []\n",
        "    aux_loss = 0.1\n",
        "    aux_acc = 0.90\n",
        "\n",
        "    for epoch in range(0, epochs):\n",
        "        model.train()\n",
        "        train_loss, train_acc, train_prec, train_recall, train_f1 = [], [], [], [], []\n",
        "        for batch in iter(train_dataloader):\n",
        "            X, Y = batch\n",
        "            X, Y = X.to(device, torch.float32), Y.to(device, torch.float32)\n",
        "            optimizer.zero_grad()\n",
        "            Y_hat = model(X)\n",
        "            loss = loss_fn(Y_hat, Y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            \n",
        "            # Metricas\n",
        "            acc, prec, recall, f1 = Metrics(Y, Y_hat, device, 'weighted')\n",
        "            \n",
        "            train_acc.append(acc)\n",
        "            train_prec.append(prec) \n",
        "            train_recall.append(recall)\n",
        "            train_f1.append(f1)\n",
        "        \n",
        "        # Validacion\n",
        "        model.eval()\n",
        "        val_loss, val_acc, val_prec, val_recall, val_f1 = [], [], [], [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in iter(val_dataloader):\n",
        "                X, Y = batch\n",
        "                X, Y = X.to(device, torch.float32), Y.to(device, torch.float32)\n",
        "                Y_hat = model(X)\n",
        "                loss = loss_fn(Y_hat, Y)\n",
        "                val_loss.append(loss.item())\n",
        "\n",
        "                # Metricas\n",
        "                acc, prec, recall, f1 = Metrics(Y, Y_hat, device, 'weighted')\n",
        "\n",
        "                val_acc.append(acc)\n",
        "                val_prec.append(prec) \n",
        "                val_recall.append(recall)\n",
        "                val_f1.append(f1)\n",
        "\n",
        "        #scheduler.step() \n",
        "        print(f\"Learning rate: {scheduler.get_last_lr()}\")   \n",
        "        print(f\"Epoca:{epoch + 1}/{epochs} \\n\")\n",
        "        print(f\"train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f} \\n\")\n",
        "        print(f\"train acc: {np.mean(train_acc):.5f}, val acc: {np.mean(val_acc):.5f} \\n\")\n",
        "        print(f\"train prec: {np.mean(train_prec):.5f}, val prec: {np.mean(val_prec):.5f} \\n\")\n",
        "        print(f\"train recall: {np.mean(train_recall):.5f}, val recall: {np.mean(val_recall):.5f} \\n\")\n",
        "        print(f\"train f1: {np.mean(train_f1):.5f}, val f1: {np.mean(val_f1):.5f} \\n\")\n",
        "\n",
        "        if(np.mean(val_loss) < aux_loss):\n",
        "          aux_loss = np.mean(val_loss)\n",
        "          print(\"Menor perdida en validacion  = \", aux_loss, \" en la epoca: \", epoch, \"\\n\")\n",
        "\n",
        "        if(np.mean(val_acc) > aux_acc):\n",
        "          torch.save(model.state_dict(), 'drive/MyDrive/Colab_Notebooks/Tesis/Models/Binary_model.pt')\n",
        "          aux_acc = np.mean(val_acc)\n",
        "          print(\"----------------------------------------\")\n",
        "          print(\"Modelo guardado con Accuracy = \", aux_acc)\n",
        "          print(\"----------------------------------------\")\n",
        "        print('**************************************************************************************************')\n",
        "\n",
        "        training_loss.append(np.mean(train_loss))\n",
        "        validation_loss.append(np.mean(val_loss))\n",
        "   \n",
        "    return training_loss, validation_loss, lr_per_epoch, val_acc_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mTX0kyNoN4lp"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_dataloader, device):  \n",
        "    \n",
        "    model.load_state_dict(torch.load('drive/MyDrive/Colab_Notebooks/Tesis/Models/(best)Binary_model.pt', map_location=device))\n",
        "    print(\"Modelo cargado.\\n\")\n",
        "    \n",
        "    model.to(device)\n",
        "    \n",
        "    model.eval()\n",
        "    test_loss, test_acc, test_prec, test_recall, test_f1 = [], [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in iter(test_dataloader):\n",
        "            X, Y = batch\n",
        "            X, Y = X.to(device, torch.float32), Y.to(device, torch.float32)\n",
        "            Y_hat = model(X)\n",
        "\n",
        "            # Metricas\n",
        "            acc, prec, recall, f1 = Metrics(Y, Y_hat, device, 'weighted')\n",
        "            \n",
        "            test_acc.append(acc)\n",
        "            test_prec.append(prec) \n",
        "            test_recall.append(recall)\n",
        "            test_f1.append(f1)\n",
        "\n",
        "            print('Y: ', Y)\n",
        "            print('Y_hat: ', Y_hat)\n",
        "    \n",
        "    return (np.mean(test_acc), np.mean(test_prec), np.mean(test_recall), np.mean(test_f1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451,
          "referenced_widgets": [
            "6564bc7d6fd94d41aa106365b40674c9",
            "d22e415067a049d593da9ab24b93ceed",
            "29a5ceaca6594a42b88045107de3bbd6",
            "a8561e21f81f4ea981abfff5321188d0",
            "40c45dc9510b48e78312e2d138de99a9",
            "e9aa2eab80d5428fbbacdd0cbff8a784",
            "45c2e2891ea040b990d7865a1e65c396",
            "8bd0907b463c461daa296a32ee97e2f9",
            "e2c32f192b114d3da2205dcdf768e947",
            "dd4658bd80bf4893b1dc4a6770a5dacb",
            "c81917817936469093eeaba0c4a955c1"
          ]
        },
        "id": "WqjiS6iSigqB",
        "outputId": "f015ab5d-c27f-42e8-da29-966c1d3f315e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/77.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6564bc7d6fd94d41aa106365b40674c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "import torchvision.models as models\n",
        "import timm\n",
        "\n",
        "# Creacion del modelo\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#model = models.alexnet(pretrained=True)\n",
        "model = models.densenet201(pretrained=True)\n",
        "#model = timm.create_model('inception_resnet_v2', pretrained=True)\n",
        "binary_model = MyExtendedNet(model)\n",
        "\n",
        "#binary_model = InmunoNet(3, 1)\n",
        "#loss_fn = nn.BCELoss()\n",
        "loss_fn = nn.CrossEntropyLoss(weight=weights)\n",
        "epochs = 50\n",
        "if torch.cuda.is_available():\n",
        "    binary_model.to(device)\n",
        "    weights = torch.tensor(weights, device=device)\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(binary_model.parameters(), lr = 0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6Mpuo9c-6Efz",
        "outputId": "629a2e53-f10d-4785-f8ec-0b64eae6f09a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: [0.0001]\n",
            "Epoca:1/50 \n",
            "\n",
            "train loss: 0.20636, val loss: 0.27259 \n",
            "\n",
            "train acc: 0.66026, val acc: 0.36424 \n",
            "\n",
            "train prec: 0.75685, val prec: 0.93760 \n",
            "\n",
            "train recall: 0.69358, val recall: 0.36424 \n",
            "\n",
            "train f1: 0.71071, val f1: 0.45970 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:2/50 \n",
            "\n",
            "train loss: 0.17747, val loss: 0.13891 \n",
            "\n",
            "train acc: 0.82292, val acc: 0.86721 \n",
            "\n",
            "train prec: 0.88659, val prec: 0.94903 \n",
            "\n",
            "train recall: 0.86268, val recall: 0.86721 \n",
            "\n",
            "train f1: 0.87091, val f1: 0.90095 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:3/50 \n",
            "\n",
            "train loss: 0.16270, val loss: 0.21529 \n",
            "\n",
            "train acc: 0.85581, val acc: 0.57114 \n",
            "\n",
            "train prec: 0.92316, val prec: 0.92760 \n",
            "\n",
            "train recall: 0.87952, val recall: 0.57114 \n",
            "\n",
            "train f1: 0.89800, val f1: 0.67526 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:4/50 \n",
            "\n",
            "train loss: 0.15644, val loss: 0.17937 \n",
            "\n",
            "train acc: 0.88072, val acc: 0.71633 \n",
            "\n",
            "train prec: 0.93626, val prec: 0.93144 \n",
            "\n",
            "train recall: 0.89608, val recall: 0.71633 \n",
            "\n",
            "train f1: 0.91279, val f1: 0.79635 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:5/50 \n",
            "\n",
            "train loss: 0.15176, val loss: 0.14096 \n",
            "\n",
            "train acc: 0.89904, val acc: 0.86486 \n",
            "\n",
            "train prec: 0.94489, val prec: 0.94334 \n",
            "\n",
            "train recall: 0.91529, val recall: 0.86486 \n",
            "\n",
            "train f1: 0.92735, val f1: 0.89749 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:6/50 \n",
            "\n",
            "train loss: 0.15265, val loss: 0.18566 \n",
            "\n",
            "train acc: 0.89835, val acc: 0.68508 \n",
            "\n",
            "train prec: 0.94061, val prec: 0.93887 \n",
            "\n",
            "train recall: 0.91218, val recall: 0.68508 \n",
            "\n",
            "train f1: 0.92359, val f1: 0.77096 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:7/50 \n",
            "\n",
            "train loss: 0.14625, val loss: 0.15110 \n",
            "\n",
            "train acc: 0.91661, val acc: 0.82392 \n",
            "\n",
            "train prec: 0.95282, val prec: 0.94313 \n",
            "\n",
            "train recall: 0.93249, val recall: 0.82392 \n",
            "\n",
            "train f1: 0.94059, val f1: 0.86971 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:8/50 \n",
            "\n",
            "train loss: 0.15309, val loss: 0.16101 \n",
            "\n",
            "train acc: 0.90876, val acc: 0.79322 \n",
            "\n",
            "train prec: 0.93987, val prec: 0.93783 \n",
            "\n",
            "train recall: 0.92568, val recall: 0.79322 \n",
            "\n",
            "train f1: 0.93067, val f1: 0.84837 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:9/50 \n",
            "\n",
            "train loss: 0.15414, val loss: 0.16091 \n",
            "\n",
            "train acc: 0.89873, val acc: 0.78385 \n",
            "\n",
            "train prec: 0.93437, val prec: 0.94476 \n",
            "\n",
            "train recall: 0.91376, val recall: 0.78385 \n",
            "\n",
            "train f1: 0.92096, val f1: 0.84383 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:10/50 \n",
            "\n",
            "train loss: 0.14763, val loss: 0.16690 \n",
            "\n",
            "train acc: 0.91794, val acc: 0.76599 \n",
            "\n",
            "train prec: 0.95182, val prec: 0.93711 \n",
            "\n",
            "train recall: 0.93271, val recall: 0.76599 \n",
            "\n",
            "train f1: 0.94040, val f1: 0.83141 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:11/50 \n",
            "\n",
            "train loss: 0.14542, val loss: 0.15430 \n",
            "\n",
            "train acc: 0.92254, val acc: 0.79735 \n",
            "\n",
            "train prec: 0.95566, val prec: 0.94386 \n",
            "\n",
            "train recall: 0.93475, val recall: 0.79735 \n",
            "\n",
            "train f1: 0.94327, val f1: 0.85485 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:12/50 \n",
            "\n",
            "train loss: 0.14134, val loss: 0.14702 \n",
            "\n",
            "train acc: 0.93801, val acc: 0.83998 \n",
            "\n",
            "train prec: 0.96426, val prec: 0.94309 \n",
            "\n",
            "train recall: 0.95209, val recall: 0.83998 \n",
            "\n",
            "train f1: 0.95710, val f1: 0.88292 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:13/50 \n",
            "\n",
            "train loss: 0.14301, val loss: 0.12955 \n",
            "\n",
            "train acc: 0.93103, val acc: 0.90493 \n",
            "\n",
            "train prec: 0.96200, val prec: 0.95455 \n",
            "\n",
            "train recall: 0.94384, val recall: 0.90493 \n",
            "\n",
            "train f1: 0.95133, val f1: 0.92637 \n",
            "\n",
            "----------------------------------------\n",
            "Modelo guardado con Accuracy =  0.9049326697892272\n",
            "----------------------------------------\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:14/50 \n",
            "\n",
            "train loss: 0.14236, val loss: 0.13312 \n",
            "\n",
            "train acc: 0.93414, val acc: 0.88027 \n",
            "\n",
            "train prec: 0.96720, val prec: 0.95640 \n",
            "\n",
            "train recall: 0.94453, val recall: 0.88027 \n",
            "\n",
            "train f1: 0.95439, val f1: 0.91254 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:15/50 \n",
            "\n",
            "train loss: 0.13928, val loss: 0.15644 \n",
            "\n",
            "train acc: 0.94365, val acc: 0.79032 \n",
            "\n",
            "train prec: 0.97427, val prec: 0.94234 \n",
            "\n",
            "train recall: 0.95225, val recall: 0.79032 \n",
            "\n",
            "train f1: 0.96224, val f1: 0.84958 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:16/50 \n",
            "\n",
            "train loss: 0.13858, val loss: 0.17281 \n",
            "\n",
            "train acc: 0.94813, val acc: 0.73207 \n",
            "\n",
            "train prec: 0.97782, val prec: 0.94223 \n",
            "\n",
            "train recall: 0.95019, val recall: 0.73207 \n",
            "\n",
            "train f1: 0.96282, val f1: 0.80610 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:17/50 \n",
            "\n",
            "train loss: 0.14028, val loss: 0.27344 \n",
            "\n",
            "train acc: 0.93892, val acc: 0.36549 \n",
            "\n",
            "train prec: 0.97416, val prec: 0.93356 \n",
            "\n",
            "train recall: 0.93935, val recall: 0.36549 \n",
            "\n",
            "train f1: 0.95502, val f1: 0.46077 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:18/50 \n",
            "\n",
            "train loss: 0.14219, val loss: 0.14000 \n",
            "\n",
            "train acc: 0.93525, val acc: 0.86486 \n",
            "\n",
            "train prec: 0.96934, val prec: 0.94663 \n",
            "\n",
            "train recall: 0.93559, val recall: 0.86486 \n",
            "\n",
            "train f1: 0.95045, val f1: 0.90016 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:19/50 \n",
            "\n",
            "train loss: 0.13827, val loss: 0.17587 \n",
            "\n",
            "train acc: 0.94647, val acc: 0.72069 \n",
            "\n",
            "train prec: 0.98036, val prec: 0.93559 \n",
            "\n",
            "train recall: 0.94673, val recall: 0.72069 \n",
            "\n",
            "train f1: 0.96237, val f1: 0.79734 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:20/50 \n",
            "\n",
            "train loss: 0.13817, val loss: 0.16228 \n",
            "\n",
            "train acc: 0.94829, val acc: 0.76800 \n",
            "\n",
            "train prec: 0.98017, val prec: 0.93973 \n",
            "\n",
            "train recall: 0.94846, val recall: 0.76800 \n",
            "\n",
            "train f1: 0.96300, val f1: 0.83508 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:21/50 \n",
            "\n",
            "train loss: 0.13866, val loss: 0.18606 \n",
            "\n",
            "train acc: 0.94814, val acc: 0.65797 \n",
            "\n",
            "train prec: 0.97934, val prec: 0.93718 \n",
            "\n",
            "train recall: 0.94822, val recall: 0.65797 \n",
            "\n",
            "train f1: 0.96260, val f1: 0.75378 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:22/50 \n",
            "\n",
            "train loss: 0.14780, val loss: 0.14581 \n",
            "\n",
            "train acc: 0.92442, val acc: 0.83965 \n",
            "\n",
            "train prec: 0.96117, val prec: 0.94496 \n",
            "\n",
            "train recall: 0.92476, val recall: 0.83965 \n",
            "\n",
            "train f1: 0.94097, val f1: 0.88375 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:23/50 \n",
            "\n",
            "train loss: 0.14029, val loss: 0.14078 \n",
            "\n",
            "train acc: 0.94134, val acc: 0.86018 \n",
            "\n",
            "train prec: 0.97687, val prec: 0.94311 \n",
            "\n",
            "train recall: 0.94168, val recall: 0.86018 \n",
            "\n",
            "train f1: 0.95778, val f1: 0.89629 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:24/50 \n",
            "\n",
            "train loss: 0.13785, val loss: 0.14216 \n",
            "\n",
            "train acc: 0.94621, val acc: 0.83753 \n",
            "\n",
            "train prec: 0.98160, val prec: 0.95009 \n",
            "\n",
            "train recall: 0.94656, val recall: 0.83753 \n",
            "\n",
            "train f1: 0.96279, val f1: 0.88514 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:25/50 \n",
            "\n",
            "train loss: 0.13575, val loss: 0.14188 \n",
            "\n",
            "train acc: 0.95530, val acc: 0.83306 \n",
            "\n",
            "train prec: 0.98487, val prec: 0.95132 \n",
            "\n",
            "train recall: 0.95548, val recall: 0.83306 \n",
            "\n",
            "train f1: 0.96918, val f1: 0.88301 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:26/50 \n",
            "\n",
            "train loss: 0.13699, val loss: 0.13784 \n",
            "\n",
            "train acc: 0.94937, val acc: 0.86911 \n",
            "\n",
            "train prec: 0.98450, val prec: 0.94701 \n",
            "\n",
            "train recall: 0.94954, val recall: 0.86911 \n",
            "\n",
            "train f1: 0.96589, val f1: 0.90308 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:27/50 \n",
            "\n",
            "train loss: 0.13599, val loss: 0.15614 \n",
            "\n",
            "train acc: 0.95218, val acc: 0.81576 \n",
            "\n",
            "train prec: 0.98563, val prec: 0.92257 \n",
            "\n",
            "train recall: 0.95218, val recall: 0.81576 \n",
            "\n",
            "train f1: 0.96784, val f1: 0.86287 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:28/50 \n",
            "\n",
            "train loss: 0.13608, val loss: 0.17263 \n",
            "\n",
            "train acc: 0.95328, val acc: 0.72984 \n",
            "\n",
            "train prec: 0.98422, val prec: 0.93711 \n",
            "\n",
            "train recall: 0.95362, val recall: 0.72984 \n",
            "\n",
            "train f1: 0.96792, val f1: 0.80676 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:29/50 \n",
            "\n",
            "train loss: 0.13524, val loss: 0.21553 \n",
            "\n",
            "train acc: 0.95483, val acc: 0.56411 \n",
            "\n",
            "train prec: 0.98641, val prec: 0.93111 \n",
            "\n",
            "train recall: 0.95500, val recall: 0.56411 \n",
            "\n",
            "train f1: 0.96978, val f1: 0.67232 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:30/50 \n",
            "\n",
            "train loss: 0.13537, val loss: 0.15076 \n",
            "\n",
            "train acc: 0.95784, val acc: 0.82212 \n",
            "\n",
            "train prec: 0.98531, val prec: 0.94422 \n",
            "\n",
            "train recall: 0.95784, val recall: 0.82212 \n",
            "\n",
            "train f1: 0.97073, val f1: 0.87098 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:31/50 \n",
            "\n",
            "train loss: 0.14515, val loss: 0.12515 \n",
            "\n",
            "train acc: 0.93409, val acc: 0.92780 \n",
            "\n",
            "train prec: 0.96560, val prec: 0.96353 \n",
            "\n",
            "train recall: 0.93426, val recall: 0.92780 \n",
            "\n",
            "train f1: 0.94799, val f1: 0.94337 \n",
            "\n",
            "----------------------------------------\n",
            "Modelo guardado con Accuracy =  0.9278029859484777\n",
            "----------------------------------------\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:32/50 \n",
            "\n",
            "train loss: 0.14342, val loss: 0.13828 \n",
            "\n",
            "train acc: 0.93602, val acc: 0.87123 \n",
            "\n",
            "train prec: 0.97011, val prec: 0.94307 \n",
            "\n",
            "train recall: 0.93645, val recall: 0.87123 \n",
            "\n",
            "train f1: 0.95162, val f1: 0.90204 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:33/50 \n",
            "\n",
            "train loss: 0.13701, val loss: 0.14425 \n",
            "\n",
            "train acc: 0.95017, val acc: 0.83954 \n",
            "\n",
            "train prec: 0.98331, val prec: 0.94844 \n",
            "\n",
            "train recall: 0.95034, val recall: 0.83954 \n",
            "\n",
            "train f1: 0.96567, val f1: 0.88395 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:34/50 \n",
            "\n",
            "train loss: 0.13562, val loss: 0.17886 \n",
            "\n",
            "train acc: 0.95397, val acc: 0.70964 \n",
            "\n",
            "train prec: 0.98488, val prec: 0.94145 \n",
            "\n",
            "train recall: 0.95405, val recall: 0.70964 \n",
            "\n",
            "train f1: 0.96849, val f1: 0.79277 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:35/50 \n",
            "\n",
            "train loss: 0.13546, val loss: 0.19104 \n",
            "\n",
            "train acc: 0.95669, val acc: 0.68487 \n",
            "\n",
            "train prec: 0.98456, val prec: 0.93001 \n",
            "\n",
            "train recall: 0.95677, val recall: 0.68487 \n",
            "\n",
            "train f1: 0.96971, val f1: 0.77031 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:36/50 \n",
            "\n",
            "train loss: 0.13461, val loss: 0.15081 \n",
            "\n",
            "train acc: 0.95741, val acc: 0.81989 \n",
            "\n",
            "train prec: 0.98690, val prec: 0.94505 \n",
            "\n",
            "train recall: 0.95775, val recall: 0.81989 \n",
            "\n",
            "train f1: 0.97145, val f1: 0.87058 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:37/50 \n",
            "\n",
            "train loss: 0.13617, val loss: 0.18432 \n",
            "\n",
            "train acc: 0.95413, val acc: 0.68274 \n",
            "\n",
            "train prec: 0.98303, val prec: 0.93245 \n",
            "\n",
            "train recall: 0.95490, val recall: 0.68274 \n",
            "\n",
            "train f1: 0.96795, val f1: 0.77083 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:38/50 \n",
            "\n",
            "train loss: 0.13449, val loss: 0.19474 \n",
            "\n",
            "train acc: 0.95908, val acc: 0.65362 \n",
            "\n",
            "train prec: 0.98743, val prec: 0.93119 \n",
            "\n",
            "train recall: 0.95917, val recall: 0.65362 \n",
            "\n",
            "train f1: 0.97251, val f1: 0.74813 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:39/50 \n",
            "\n",
            "train loss: 0.13840, val loss: 0.17620 \n",
            "\n",
            "train acc: 0.94613, val acc: 0.73899 \n",
            "\n",
            "train prec: 0.97843, val prec: 0.92709 \n",
            "\n",
            "train recall: 0.94630, val recall: 0.73899 \n",
            "\n",
            "train f1: 0.96114, val f1: 0.81118 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:40/50 \n",
            "\n",
            "train loss: 0.14698, val loss: 0.14232 \n",
            "\n",
            "train acc: 0.92442, val acc: 0.85125 \n",
            "\n",
            "train prec: 0.96258, val prec: 0.94753 \n",
            "\n",
            "train recall: 0.92450, val recall: 0.85125 \n",
            "\n",
            "train f1: 0.94103, val f1: 0.89080 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:41/50 \n",
            "\n",
            "train loss: 0.13934, val loss: 0.13688 \n",
            "\n",
            "train acc: 0.94306, val acc: 0.86655 \n",
            "\n",
            "train prec: 0.97856, val prec: 0.95548 \n",
            "\n",
            "train recall: 0.94315, val recall: 0.86655 \n",
            "\n",
            "train f1: 0.95943, val f1: 0.90423 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:42/50 \n",
            "\n",
            "train loss: 0.13507, val loss: 0.15628 \n",
            "\n",
            "train acc: 0.95766, val acc: 0.79043 \n",
            "\n",
            "train prec: 0.98683, val prec: 0.94323 \n",
            "\n",
            "train recall: 0.95783, val recall: 0.79043 \n",
            "\n",
            "train f1: 0.97148, val f1: 0.85184 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:43/50 \n",
            "\n",
            "train loss: 0.13663, val loss: 0.14045 \n",
            "\n",
            "train acc: 0.95019, val acc: 0.85806 \n",
            "\n",
            "train prec: 0.98182, val prec: 0.95327 \n",
            "\n",
            "train recall: 0.95027, val recall: 0.85806 \n",
            "\n",
            "train f1: 0.96477, val f1: 0.89656 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:44/50 \n",
            "\n",
            "train loss: 0.13570, val loss: 0.13684 \n",
            "\n",
            "train acc: 0.95560, val acc: 0.88049 \n",
            "\n",
            "train prec: 0.98481, val prec: 0.94497 \n",
            "\n",
            "train recall: 0.95568, val recall: 0.88049 \n",
            "\n",
            "train f1: 0.96927, val f1: 0.90877 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:45/50 \n",
            "\n",
            "train loss: 0.13613, val loss: 0.14242 \n",
            "\n",
            "train acc: 0.95182, val acc: 0.84913 \n",
            "\n",
            "train prec: 0.98513, val prec: 0.94767 \n",
            "\n",
            "train recall: 0.95182, val recall: 0.84913 \n",
            "\n",
            "train f1: 0.96740, val f1: 0.88957 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:46/50 \n",
            "\n",
            "train loss: 0.13472, val loss: 0.15708 \n",
            "\n",
            "train acc: 0.95699, val acc: 0.79043 \n",
            "\n",
            "train prec: 0.98777, val prec: 0.94467 \n",
            "\n",
            "train recall: 0.95699, val recall: 0.79043 \n",
            "\n",
            "train f1: 0.97157, val f1: 0.84864 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:47/50 \n",
            "\n",
            "train loss: 0.13366, val loss: 0.15930 \n",
            "\n",
            "train acc: 0.95825, val acc: 0.77481 \n",
            "\n",
            "train prec: 0.99079, val prec: 0.94975 \n",
            "\n",
            "train recall: 0.95842, val recall: 0.77481 \n",
            "\n",
            "train f1: 0.97386, val f1: 0.83860 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:48/50 \n",
            "\n",
            "train loss: 0.13361, val loss: 0.16082 \n",
            "\n",
            "train acc: 0.96110, val acc: 0.78352 \n",
            "\n",
            "train prec: 0.98966, val prec: 0.94292 \n",
            "\n",
            "train recall: 0.96144, val recall: 0.78352 \n",
            "\n",
            "train f1: 0.97481, val f1: 0.84292 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:49/50 \n",
            "\n",
            "train loss: 0.13774, val loss: 0.14218 \n",
            "\n",
            "train acc: 0.94770, val acc: 0.86721 \n",
            "\n",
            "train prec: 0.98203, val prec: 0.93783 \n",
            "\n",
            "train recall: 0.94787, val recall: 0.86721 \n",
            "\n",
            "train f1: 0.96365, val f1: 0.89722 \n",
            "\n",
            "**************************************************************************************************\n",
            "Learning rate: [0.0001]\n",
            "Epoca:50/50 \n",
            "\n",
            "train loss: 0.13882, val loss: 0.13805 \n",
            "\n",
            "train acc: 0.94539, val acc: 0.88517 \n",
            "\n",
            "train prec: 0.97875, val prec: 0.93848 \n",
            "\n",
            "train recall: 0.94548, val recall: 0.88517 \n",
            "\n",
            "train f1: 0.96046, val f1: 0.90811 \n",
            "\n",
            "**************************************************************************************************\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2cdd6af4522e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     scheduler)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mfinal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-12620ce6a802>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, loss_fn, train_dataloader, val_dataloader, epochs, device, scheduler)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'lr_per_epoch' is not defined"
          ]
        }
      ],
      "source": [
        "# Entrenamiento y validacion\n",
        "\n",
        "start_time = time.time()\n",
        "training_cost, validation_cost, lr_per_epoch, val_acc_per_epoch = train_model(\n",
        "    binary_model,\n",
        "    optimizer,\n",
        "    loss_fn, \n",
        "    train_dataloader, \n",
        "    val_dataloader,  \n",
        "    epochs,\n",
        "    device,\n",
        "    scheduler)\n",
        "final_time = time.time() - start_time\n",
        "\n",
        "#print(\"Estructura del modelo: \\n\", binary_model, \"\\n\")\n",
        "print('Tiempo de entrenamiento:', round(final_time/60, 3), \" min \\n\")\n",
        "plt.plot(range(epochs), training_cost, color = \"r\", label = \"Conjunto de entrenamiento\")\n",
        "plt.plot(range(epochs), validation_cost, color = \"b\", label = \"Conjunto de validacion\")\n",
        "plt.title(\"Coste por epoca\")\n",
        "plt.xlabel(\"Epoca\")\n",
        "plt.ylabel(\"Coste\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(epochs), lr_per_epoch, color = \"r\", label = \"Tasa de aprendizaje\")\n",
        "plt.title(\"Tasa de aprendizaje por epoca\")\n",
        "plt.xlabel(\"Epoca\")\n",
        "plt.ylabel(\"Coste\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(range(epochs), val_acc_per_epoch, color = \"b\", label = \"ACC de Validacion\")\n",
        "plt.title(\"Exactitud en el conjunto de Validacion por epoca\")\n",
        "plt.xlabel(\"Epoca\")\n",
        "plt.ylabel(\"Coste\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-4aTEQZurte"
      },
      "outputs": [],
      "source": [
        "# Prueba del modelo\n",
        "\n",
        "start_time = time.time()\n",
        "test_acc, test_prec, test_recall, test_F1 = test_model(\n",
        "    binary_model, \n",
        "    test_dataloader, \n",
        "    device)\n",
        "final_time = time.time() - start_time\n",
        "print('Tiempo de test:', round(final_time/60, 3), \"\\n\")\n",
        "print(\"Metricas del test:\\n\", \"Exactitud: \", round(test_acc, 2), \" Precision: \",\n",
        "      round(test_prec, 2), \" Recall: \", round(test_recall, 2), \" F1: \", round(test_F1, 2))\n",
        "\n",
        "  # Accuracy = TP + TN / (TP + TN + FP + FN)\n",
        "  # Precision = TP / (TP + FP)\n",
        "  # Recall = TP / (TP + FN) \n",
        "  # F1 = 2 * (Precision * Recall) / (Precision + Recall)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "binary_model.ipynb",
      "provenance": [],
      "mount_file_id": "1Xmkm1usyRdYFWqlq0Xl3OqckaUXYSCKk",
      "authorship_tag": "ABX9TyMR0IaY7Zo9GLgjRdtB9UT+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6564bc7d6fd94d41aa106365b40674c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d22e415067a049d593da9ab24b93ceed",
              "IPY_MODEL_29a5ceaca6594a42b88045107de3bbd6",
              "IPY_MODEL_a8561e21f81f4ea981abfff5321188d0"
            ],
            "layout": "IPY_MODEL_40c45dc9510b48e78312e2d138de99a9"
          }
        },
        "d22e415067a049d593da9ab24b93ceed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9aa2eab80d5428fbbacdd0cbff8a784",
            "placeholder": "​",
            "style": "IPY_MODEL_45c2e2891ea040b990d7865a1e65c396",
            "value": "100%"
          }
        },
        "29a5ceaca6594a42b88045107de3bbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bd0907b463c461daa296a32ee97e2f9",
            "max": 81131730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2c32f192b114d3da2205dcdf768e947",
            "value": 81131730
          }
        },
        "a8561e21f81f4ea981abfff5321188d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd4658bd80bf4893b1dc4a6770a5dacb",
            "placeholder": "​",
            "style": "IPY_MODEL_c81917817936469093eeaba0c4a955c1",
            "value": " 77.4M/77.4M [00:00&lt;00:00, 201MB/s]"
          }
        },
        "40c45dc9510b48e78312e2d138de99a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9aa2eab80d5428fbbacdd0cbff8a784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45c2e2891ea040b990d7865a1e65c396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd0907b463c461daa296a32ee97e2f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c32f192b114d3da2205dcdf768e947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd4658bd80bf4893b1dc4a6770a5dacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81917817936469093eeaba0c4a955c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}